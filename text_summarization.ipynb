{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#downloading the reviews.txt from gdrive in Kaggle\n!gdown --id 1PYJfWCT5YB5BJFR65S7bX8ktguURP1VH","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#installing the required dependencies\n!pip install transformers peft datasets evaluate accelerate bitsandbytes langdetect googletrans==4.0.0-rc1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#clearing the cuda cache to ensure that heavy models like pegasus can be finetuned\nimport torch\ntorch.cuda.empty_cache()\ntorch.cuda.ipc_collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T15:52:38.584905Z","iopub.execute_input":"2025-02-12T15:52:38.585131Z","iopub.status.idle":"2025-02-12T15:52:40.276093Z","shell.execute_reply.started":"2025-02-12T15:52:38.585112Z","shell.execute_reply":"2025-02-12T15:52:40.275431Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#importing the required packages and dependencies\nimport torch\nfrom transformers import PegasusTokenizer, PegasusForConditionalGeneration, TrainingArguments, Trainer, pipeline\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, BartTokenizer, BartForConditionalGeneration, MT5Tokenizer, MT5ForConditionalGeneration\nfrom datasets import Dataset\nfrom peft import get_peft_model, LoraConfig, TaskType\nimport evaluate\nfrom langdetect import detect\nfrom googletrans import Translator\nimport logging\nimport datasets\nimport transformers\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ntransformers.logging.set_verbosity_error()\ndatasets.logging.set_verbosity_error()\nlogging.getLogger(\"transformers\").setLevel(logging.ERROR)\n\n#initialising the translator to translate hindi comments to english\ntranslator = Translator()\n\n#using kaggle's GPUs for finetuning purpose\ntorch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n#initialising the bart tokenizer and model to be used for generation of pseudo labels\nbart_tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\nbart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\").to(torch_device)\n\ndef generate_pseudo_label_bart(text):\n    \"\"\"Function for generating the pseudo labels using BART\"\"\"\n    inputs = bart_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(torch_device)\n    output = bart_model.generate(**inputs, max_length=100, min_length=20)\n    return bart_tokenizer.decode(output[0], skip_special_tokens=True)\n\ndef load_and_preprocess(model_name):\n    \"\"\"\n    Function for loading and pre-processing the dataset which\n    includes translation, tokenization as well as pseudo-label\n    generation.\n    \"\"\"\n    with open(\"reviews.txt\", \"r\", encoding=\"utf-8\") as file:\n        reviews = file.readlines()\n    \n    reviews = [review.strip() for review in reviews if review.strip()]\n    processed_reviews = []\n\n    #translating the reviews\n    for review in reviews:\n        try:\n            lang = detect(review)\n            if lang == \"hi\":\n                translated_text = translator.translate(review, src=\"hi\", dest=\"en\").text\n                processed_reviews.append(f\"Original: {review}\\nTranslated: {translated_text}\")\n            else:\n                processed_reviews.append(review)\n        except:\n            processed_reviews.append(review)\n\n    dataset = Dataset.from_dict({\"text\": processed_reviews})\n\n    #initilising the model and tokenizer based on model_name\n    if model_name == \"pegasus\":\n        tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")\n        model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\").to(torch_device)\n    elif model_name == \"mt5\":\n        tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-small\")\n        model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\").to(torch_device)\n    else:\n        tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n        model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\").to(torch_device)\n\n    def generate_pseudo_label(example):\n        \"\"\"Function for generating the pseudo labels\"\"\"\n        input_text = example[\"text\"]\n        summary = generate_pseudo_label_bart(input_text)\n    \n        tokenized_input = tokenizer(input_text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n        tokenized_summary = tokenizer(summary, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n    \n        labels = tokenized_summary[\"input_ids\"].squeeze().tolist()\n        labels = [label if label != tokenizer.pad_token_id else -100 for label in labels]\n    \n        return {\n            \"input_ids\": tokenized_input[\"input_ids\"].squeeze().tolist(),\n            \"attention_mask\": tokenized_input[\"attention_mask\"].squeeze().tolist(),\n            \"labels\": labels\n        }\n    dataset = dataset.map(generate_pseudo_label, batched=False)\n\n    \n    if dataset is None or len(dataset) == 0:\n        raise ValueError(\"Dataset mapping failed. Check data preprocessing.\")\n    \n    print(f\"Dataset size: {len(dataset)}\")\n    print(f\"Tokenizer loaded: {tokenizer}\")\n    \n    return dataset.train_test_split(test_size=0.1), tokenizer\n\ndef load_lora_model(model_name):\n    \"\"\"\n    Function for loading the model and setting up LoRA\n    config based on the model_name sent when the function\n    is called.\n    \"\"\"\n    if model_name == \"pegasus\":\n        model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\").to(torch_device)\n    elif model_name == \"mt5\":\n        model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\").to(torch_device)\n    else:\n        model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\").to(torch_device)\n\n    if model_name == \"pegasus\":\n        lora_config = LoraConfig(\n            task_type=TaskType.SEQ_2_SEQ_LM,\n            inference_mode=False,\n            r=8,\n            lora_alpha=32,\n            lora_dropout=0.1,\n            target_modules=[\"q_proj\", \"v_proj\"]\n        )\n    elif model_name == \"mt5\":\n        lora_config = LoraConfig(\n            task_type=TaskType.SEQ_2_SEQ_LM,\n            inference_mode=False,\n            r=8,\n            lora_alpha=32,\n            lora_dropout=0.1,\n            target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"wi\", \"wo\"]\n        )\n    else:\n        lora_config = LoraConfig(\n            task_type=TaskType.SEQ_2_SEQ_LM,\n            inference_mode=False,\n            r=8,\n            lora_alpha=32,\n            lora_dropout=0.1,\n            target_modules=[\"encoder.block.0.layer.0.SelfAttention.q\", \n                    \"encoder.block.0.layer.0.SelfAttention.v\", \n                    \"encoder.block.0.layer.1.DenseReluDense.wi\"]\n        )\n    \n    model = get_peft_model(model, lora_config)\n    return model\n\ndef fine_tune(model_name):\n    \"\"\"\n    Function for fine-tuning using LoRA for the\n    specified model_name.\n    \"\"\"\n    dataset, tokenizer = load_and_preprocess(model_name)\n    model = load_lora_model(model_name)\n    \n    training_args = TrainingArguments(\n        output_dir=\"./results\",\n        num_train_epochs=20,\n        per_device_train_batch_size=2,\n        gradient_accumulation_steps=4,\n        per_device_eval_batch_size=16,\n        warmup_steps=500,\n        weight_decay=0.01,\n        logging_dir=\"./logs\",\n        logging_steps=10,\n        report_to=\"none\",\n        fp16=True,\n    )\n    \n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=dataset[\"train\"],\n        eval_dataset=dataset[\"test\"],\n    )\n    \n    trainer.train()\n    model.save_pretrained(f\"./fine_tuned_lora_{model_name}\")\n    tokenizer.save_pretrained(f\"./fine_tuned_lora_{model_name}\")\n    \n    return model, tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:49:23.348480Z","iopub.execute_input":"2025-02-12T16:49:23.348812Z","iopub.status.idle":"2025-02-12T16:49:25.656974Z","shell.execute_reply.started":"2025-02-12T16:49:23.348782Z","shell.execute_reply":"2025-02-12T16:49:25.656056Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def evaluate_model(model_name):\n    \"\"\"\n    Function for evaluating the fine-tuned model using ROUGE\n    scores with BART pseudo-labels.\n    \"\"\"\n    if model_name == \"pegasus\":\n        model = PegasusForConditionalGeneration.from_pretrained(\"./fine_tuned_lora_pegasus\").to(torch_device)\n    elif model_name == \"mt5\":\n        model = MT5ForConditionalGeneration.from_pretrained(\"./fine_tuned_lora_mt5\").to(torch_device)\n    else:\n        model = T5ForConditionalGeneration.from_pretrained(\"./fine_tuned_lora_flant5\").to(torch_device)\n\n    #get dataset and tokenizer\n    dataset, tokenizer = load_and_preprocess(model_name)\n    \n    rouge = evaluate.load(\"rouge\")\n    predictions = []\n    references = []\n    \n    for example in dataset[\"test\"][\"text\"]:\n        input_text = \"summarize: \" + example\n        inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(torch_device)\n        output = model.generate(**inputs)\n        summary = tokenizer.decode(output[0], skip_special_tokens=True)\n        \n        predictions.append(summary)\n        references.append(generate_pseudo_label_bart(example))\n    \n    scores = rouge.compute(predictions=predictions, references=references)\n    print(f\"ROUGE Evaluation Scores for {model_name} with BART pseudo-labels: {scores}\")\n    return scores\n\n\ndef evaluate_pretrained_model(model_name):\n    \"\"\"\n    Function for evaluating the pre-trained model using ROUGE\n    scores with BART pseudo-labels.\n    \"\"\"\n    if model_name == \"pegasus\":\n        model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\").to(torch_device)\n        tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")\n    elif model_name == \"mt5\":\n        model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\").to(torch_device)\n        tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-small\")\n    else:\n        model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\").to(torch_device)\n        tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n    rouge = evaluate.load(\"rouge\")\n    with open(\"reviews.txt\", \"r\", encoding=\"utf-8\") as file:\n        reviews = file.readlines()\n    \n    reviews = [review.strip() for review in reviews if review.strip()]    \n    predictions = []\n    references = []\n    \n    for review in reviews:\n        input_text = review\n        inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(torch_device)\n        output = model.generate(**inputs)\n        summary = tokenizer.decode(output[0], skip_special_tokens=True)\n        \n        predictions.append(summary)\n        references.append(generate_pseudo_label_bart(input_text))\n    \n    scores = rouge.compute(predictions=predictions, references=references)\n    print(f\"Pretrained {model_name} ROUGE Scores:\", scores)\n    return scores\n\ndef get_top_reviews():\n    \"\"\"\n    Function for getting the top 5 negative and positive\n    reviews by using distilbert for sentiment analysis.\n    \"\"\"\n    sentiment_model = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n    with open(\"reviews.txt\", \"r\", encoding=\"utf-8\") as file:\n        reviews = file.readlines()\n    \n    reviews = [review.strip() for review in reviews if review.strip()]\n    \n    sentiment_results = sentiment_model(reviews)\n    \n    scored_reviews = [(review, result[\"label\"], result[\"score\"]) for review, result in zip(reviews, sentiment_results)]\n    \n    positive_reviews = sorted([r for r in scored_reviews if r[1] == \"POSITIVE\"], key=lambda x: x[2], reverse=True)[:5]\n    negative_reviews = sorted([r for r in scored_reviews if r[1] == \"NEGATIVE\"], key=lambda x: x[2], reverse=True)[:5]\n    \n    print(\"\\nTop 5 Positive Reviews:\")\n    for review in positive_reviews:\n        print(f\"Score: {review[2]:.2f} | Review: {review[0]}\")\n    \n    print(\"\\nTop 5 Negative Reviews:\")\n    for review in negative_reviews:\n        print(f\"Score: {review[2]:.2f} | Review: {review[0]}\")\n    \n    return positive_reviews, negative_reviews","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T16:22:48.632905Z","iopub.execute_input":"2025-02-12T16:22:48.633199Z","iopub.status.idle":"2025-02-12T16:22:48.645385Z","shell.execute_reply.started":"2025-02-12T16:22:48.633177Z","shell.execute_reply":"2025-02-12T16:22:48.644632Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"fine_tune(\"pegasus\")\npretrained_pegasus_scores = evaluate_pretrained_model(\"pegasus\")\nfinetuned_pegasus_scores = evaluate_model(\"pegasus\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"The ROUGE score for fine-tuned pegasus: {finetuned_pegasus_scores}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:28:04.405787Z","iopub.execute_input":"2025-02-12T17:28:04.406117Z","iopub.status.idle":"2025-02-12T17:28:04.410128Z","shell.execute_reply.started":"2025-02-12T17:28:04.406089Z","shell.execute_reply":"2025-02-12T17:28:04.409158Z"}},"outputs":[{"name":"stdout","text":"The ROUGE score for fine-tuned pegasus: {'rouge1': 0.33613923458043454, 'rouge2': 0.2616487813643875, 'rougeL': 0.3241700244419172, 'rougeLsum': 0.3228415488320868}\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"print(f\"The ROUGE score for pre-trained pegasus: {pretrained_pegasus_scores}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:28:09.460577Z","iopub.execute_input":"2025-02-12T17:28:09.460902Z","iopub.status.idle":"2025-02-12T17:28:09.465382Z","shell.execute_reply.started":"2025-02-12T17:28:09.460876Z","shell.execute_reply":"2025-02-12T17:28:09.464527Z"}},"outputs":[{"name":"stdout","text":"The ROUGE score for pre-trained pegasus: {'rouge1': 0.2907037477675651, 'rouge2': 0.1863888422657444, 'rougeL': 0.2569151688079649, 'rougeLsum': 0.25798304063359023}\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"fine_tune(\"mt5\")\npretrained_mt5_scores = evaluate_pretrained_model(\"mt5\")\nfinetuned_mt5_scores = evaluate_model(\"mt5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"The ROUGE score for fine-tuned MT5: {finetuned_mt5_scores}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:56:10.087150Z","iopub.execute_input":"2025-02-12T17:56:10.087551Z","iopub.status.idle":"2025-02-12T17:56:10.093469Z","shell.execute_reply.started":"2025-02-12T17:56:10.087516Z","shell.execute_reply":"2025-02-12T17:56:10.092482Z"}},"outputs":[{"name":"stdout","text":"The ROUGE score for fine-tuned MT5: {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"print(f\"The ROUGE score for pre-trained MT5: {pretrained_mt5_scores}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:56:12.609732Z","iopub.execute_input":"2025-02-12T17:56:12.610025Z","iopub.status.idle":"2025-02-12T17:56:12.614189Z","shell.execute_reply.started":"2025-02-12T17:56:12.610003Z","shell.execute_reply":"2025-02-12T17:56:12.613334Z"}},"outputs":[{"name":"stdout","text":"The ROUGE score for pre-trained MT5: {'rouge1': 0.003497536945812808, 'rouge2': 0.0022407407407407406, 'rougeL': 0.003968253968253968, 'rougeLsum': 0.004053092501368363}\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"fine_tune(\"flant5\")\npretrained_flant5_scores = evaluate_pretrained_model(\"flant5\")\nfinetuned_flant5_scores = evaluate_model(\"flant5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"The ROUGE score for fine-tuned Flan-T5: {finetuned_flant5_scores}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:29:06.887510Z","iopub.execute_input":"2025-02-12T17:29:06.887807Z","iopub.status.idle":"2025-02-12T17:29:06.892205Z","shell.execute_reply.started":"2025-02-12T17:29:06.887784Z","shell.execute_reply":"2025-02-12T17:29:06.891523Z"}},"outputs":[{"name":"stdout","text":"The ROUGE score for fine-tuned Flan-T5: {'rouge1': 0.2988225644999838, 'rouge2': 0.202988084904916, 'rougeL': 0.29381187578422596, 'rougeLsum': 0.2906362346546678}\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"print(f\"The ROUGE score for pre-trained Flan-T5: {pretrained_flant5_scores}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:29:35.268805Z","iopub.execute_input":"2025-02-12T17:29:35.269108Z","iopub.status.idle":"2025-02-12T17:29:35.273876Z","shell.execute_reply.started":"2025-02-12T17:29:35.269083Z","shell.execute_reply":"2025-02-12T17:29:35.272987Z"}},"outputs":[{"name":"stdout","text":"The ROUGE score for pre-trained Flan-T5: {'rouge1': 0.4482300915700921, 'rouge2': 0.3799694526109791, 'rougeL': 0.43608958796747216, 'rougeLsum': 0.4362428089990562}\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"top_5_pos_reviews, top_5_neg_reviews = get_top_reviews()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T17:03:36.417568Z","iopub.execute_input":"2025-02-12T17:03:36.417906Z","iopub.status.idle":"2025-02-12T17:03:37.249481Z","shell.execute_reply.started":"2025-02-12T17:03:36.417879Z","shell.execute_reply":"2025-02-12T17:03:37.248738Z"}},"outputs":[{"name":"stdout","text":"\nTop 5 Positive Reviews:\nScore: 1.00 | Review: Love this app\nScore: 1.00 | Review: Its awesome app\nScore: 1.00 | Review: Perfect app for influencer. Very simple , easy to use, I love it\nScore: 1.00 | Review: Nice\nScore: 1.00 | Review: This is good for creater\n\nTop 5 Negative Reviews:\nScore: 1.00 | Review: I have been applying for so many Collabs And not even a single reply Neither the app is that gud to use like it's very basic.. no help centre.. no way to get info on the applications.. no progress shown.. just a big waste app I feel ðŸ¥±\nScore: 1.00 | Review: Worst application. It doesn't let me connect my Instagram neither my YouTube. Nothing works.\nScore: 1.00 | Review: I'm not even able to connect my account to Instagram this application is showing error.not a good app\nScore: 1.00 | Review: Not good enough...\nScore: 1.00 | Review: Wasted my time... 2 months and not even a single Collab. I also raised an issue that I'm having trouble in connecting my Youtube to the app.. they asked me to send them a message on their Instagram.. I did but they did nothing about my issue.. they read and left the message like that.\n","output_type":"stream"}],"execution_count":37}]}